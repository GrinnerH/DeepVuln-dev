下面给你一份“可以直接写进论文/方案文档”的完整、可执行、不会被审稿人轻易击穿的任务定义与端到端流程说明。我会把它写成一个工程+研究双视角的规格文档：明确输入/输出、资产形态、学习阶段怎么生成、检测阶段怎么用、以及为什么这不是“给已知漏洞打补丁”。

---
1. 重新定义任务：我们做的不是“学规则”，而是“自动构建项目语义适配层”
0.1 关键定位（必须写进方案）
我们的目标不是从少量 seed 学出一个对所有项目通用的 overflow 查询；
而是学习并自动化一个“项目语义适配（semantic adaptation）”流程：
给定一个新项目，系统能自动构建一个 ProjectSemantics Pack（语义适配层），从而让 CodeQL 的官方查询在该项目上减少因语义缺失造成的漏报。
换句话说：
- CodeQL 官方查询保持不变（保证逻辑可靠、可解释、可复现）
- 我们学的是：如何把项目里隐含的容量/长度/guard/wrapper 语义，编码成 CodeQL 能消费的扩展点

---
1. 两类“可复用资产”到底是什么（文件级、内容级）
你之前要求“具体到文件、内容、生成与使用方式”，这里给你完整列表。

---
资产 A：可复用的“语义适配器生成器”（跨项目复用）
A.1 文件列表（必须存在）
1. templates/cpp/ProjectSemantics.qll.j2
2. templates/cpp/qlpack.yml.j2
3. templates/cpp/_regression_with_semantics.ql.j2（可选，或直接 prepend import）
4. tools/semantic_pack_builder.py
5. prompts/cpp/diagnose_gap.md
6. prompts/cpp/annotate_candidates.md
7. prompts/cpp/repair_pack.md（编译失败时修复用）
A.2 每个文件的内容是什么、起什么作用
1) templates/cpp/ProjectSemantics.qll.j2（核心）
作用：提供一个“可被 CodeQL 消费”的固定结构；LLM 不写 qll，LLM 只填事实，builder 渲染。
模板应明确包含 4 类扩展点（对应 4 类 gap）：
- Wrapper sink 扩展（BufferAccess/BufferWrite 子类注入）
- Capacity 语义（宏/字段表达式）
- Guard 语义（条件识别，可选）
- Source/Length 语义（用于 taint/length 相关变体，可选）
模板骨架（精简示意）：
import cpp
import semmle.code.cpp.security.BufferAccess
import semmle.code.cpp.security.BufferWrite

module ProjectSemantics {

  /** ---------- 1) Wrapper write modeling (MOST IMPORTANT) ---------- */

  predicate isWrapperWriteName(string n) {
    n = "{{WRAPPER_NAME_1}}" or n = "{{WRAPPER_NAME_2}}"
  }

  class WrapperWriteBA extends BufferAccess {
    WrapperWriteBA() {
      exists(FunctionCall c |
        isWrapperWriteName(c.getTarget().getName()) and
        this = c
      )
    }

    override Expr getBuffer()   { result = this.(FunctionCall).getArgument({{DEST_ARG}}) }
    override Expr getSizeExpr() { result = this.(FunctionCall).getArgument({{SIZE_ARG}}) }
    override int getAccessType(){ result = 2 } // write
  }

  /** ---------- 2) Capacity semantics ---------- */
  predicate isCapacityMacro(Macro m) { m.getName() = "{{CAP_MACRO}}" }

  /** ---------- 3) Guard semantics (optional) ---------- */
  predicate isProjectGuard(Expr cond) {
    // Filled by facts; can be pattern-based
    false
  }
}
关键解释（你要求“每部分含义”）：
- extends BufferAccess/BufferWrite：把“项目 wrapper”变成官方查询能枚举到的“写入抽象实例”。这是让 baseline 改变结果的主通道。
- getBuffer/getSizeExpr/getAccessType：把参数语义绑定到 CodeQL 期望的接口上。
- isCapacity* / isProjectGuard：为后续扩展（或某些官方规则）提供项目特定语义钩子。
审稿人问“你们如何保证不是幻觉？”
回答：模板固定、接口固定，LLM 只填候选名称/索引；最终是否有效由 CodeQL 回归证伪。

---
2) tools/semantic_pack_builder.py
作用：确定性“编译器”，把 SemanticFacts.json 转成 pack 目录。
输出结构（你们现在已有类似）：
semantic_packs/<project_or_iter>/pack/
  qlpack.yml
  ProjectSemantics.qll
  ProjectSemantics.llm.json   # LLM 原始事实（可审计）
  queries/_regression_with_semantics.ql

---
3) prompts/*
作用：定义 LLM 在每个阶段的职责边界（不是写 qll，而是输出 facts/patch）。
- diagnose_gap.md：从 baseline 失败中归因出 gap_kind，并提出“需要哪些语义事实”
- annotate_candidates.md：对候选集合做结构化标注（哪些是 wrapper、参数索引等）
- repair_pack.md：只允许做“语法修复/导入修复/命名冲突修复”，不允许改语义意图

---
A.3 学习阶段如何生成资产 A？
资产 A 的生成并不是“LLM 学出来”，而是系统在 seed 迭代中被调试成熟：
- seed1 跑不通 → 发现模板缺 import / 缺 override
- seed2 编译失败 → 发现 sanitize/repair 需要补规则
- seed3 A/B 无差异 → 发现需要 extends BufferAccess 而不是 taint
- ……
最终你固化出：
- 哪些扩展点必须优先
- 模板最小可行结构
- LLM 输出 JSON facts 的 schema
- repair 的自动化策略
这就是你真正从 seed 学到的“可复用方法资产”。

---
资产 B：可复用的“候选发现器 + 判据库”（跨项目复用）
这部分回答你最在意的：“不看漏洞点，新项目怎么构建语义包？”
B.1 文件列表（必须存在）
1. knowledge/cpp_overflow_lexicon.yaml（命名模式 + 判据）
2. queries/cpp/extract_wrapper_candidates.ql（CodeQL 提取候选 wrapper）
3. queries/cpp/extract_size_capacity_candidates.ql
4. queries/cpp/extract_guard_candidates.ql
5. tools/extract_candidates.py（统一执行与聚合）
6. schemas/SemanticCandidates.schema.json
7. schemas/SemanticFacts.schema.json
B.2 这些文件里具体是什么内容？
1) queries/cpp/extract_wrapper_candidates.ql
目标：不需要知道漏洞点，只需要找“可能的写入 wrapper”。
候选规则示意（不追求完美，先保证召回）：
- 函数内部调用 memcpy/strcpy/strncpy/sprintf/...
- 或者存在对指针/数组的循环写
- 或者命名匹配 copy|append|write|put|fill
输出字段（用于 LLM 标注）：
- wrapper 函数名
- 调用点样例
- 参数个数
- 某些启发式（哪一个参数像 dest，哪一个像 size）
最终由 extract_candidates.py 统一跑完，产出：
semantic_candidates.json
{
  "wrapper_candidates": [
    {
      "func": "my_memcpy",
      "evidence_calls": [
        {"file": "...", "line": 123, "call": "my_memcpy(dst, src, n)"}
      ],
      "arity": 3,
      "heuristic": {"dest_idx_guess": 0, "size_idx_guess": 2}
    }
  ],
  "capacity_candidates": [...],
  "guard_candidates": [...]
}

---
2) prompts/cpp/annotate_candidates.md
LLM 的输入：上面的候选 JSON（不是源码全文）。
LLM 的输出：SemanticFacts.json（只做分类/索引/置信度）：
{
  "wrapper_models": [
    {"name": "my_memcpy", "dest_arg": 0, "size_arg": 2, "kind": "memcpy_like", "confidence": 0.86}
  ],
  "capacity_macros": ["MAX_NAME_LEN"],
  "guard_patterns": [
    {"kind": "len_le_cap", "confidence": 0.55}
  ]
}
你要求“规模化”：这就规模化了。
LLM 不看全项目代码，只看结构化候选；静态分析负责压缩信息。

---
B.3 学习阶段如何生成资产 B？
seed 阶段的迭代会不断让你发现：
- 候选提取漏了哪类 wrapper
- guard 模式哪些写法会被忽略
- capacity 宏/字段有哪些常见形态
你把这些“失败经验”固化到：
- lexicon.yaml（模式库）
- 候选提取 query 的启发式
- LLM 标注 prompt 的判据问题
最终 B 资产就变成一个可跨项目运行的语义候选发现系统。

---
2. 完整端到端流程（学习阶段 + 检测阶段）
下面是你要的“完整流程图”，我用严格的输入输出来写。

---
Phase S：Seed 学习（Iterative Semantic Modeling）
S0：准备（Step A，脚本化）
输入：seeds/seed_cases.json
输出：workspace/seed_manifest.json（包含 db_path、baseline_query_path、vuln_file/func 等）
S1：Baseline 运行
输入：db + baseline query
输出：
- baseline.sarif
- baseline_run.json（returncode、stdout、timing）
S2：Diagnose（LLM 仅做归因，不写 qll）
输入：
- baseline.sarif（0 results）
- vuln function code（可提供，但只针对 seed）
- 相关 callsite/类型信息（可用 CodeQL slice 提供）
输出：
- GapDiagnosis.json（gap_kind + “需要哪些语义事实”）
- RequestedFactsSpec.json（例如需要 wrapper 候选/guard 候选/capacity 候选）
S3：候选提取（工具，不用 LLM）
输入：db + RequestedFactsSpec
输出：semantic_candidates.json
S4：Annotate Candidates（LLM 分类标注）
输入：semantic_candidates.json
输出：SemanticFacts.json
S5：Build Semantic Pack（确定性生成）
输入：SemanticFacts.json + templates
输出：
- semantic_packs/iter_XX/ProjectSemantics.qll
- semantic_packs/iter_XX/qlpack.yml
- semantic_packs/iter_XX/queries/_regression_with_semantics.ql
S6：Evaluate（CodeQL 证伪）
输入：db + regression query + semantic pack
输出：
- regression.sarif
- metrics.json（seed_hit_rate 等）
- ModelingRecord.json
如果 seed 命中：
- decision = converged
否则：
- decision = continue（回到 S2 或 S3，取决于失败类型：编译失败→repair；无差异→诊断扩展点）
注意：seed 阶段允许看漏洞点源码，但那只是为了“调试与验证模板/扩展点”，不是检测阶段的依赖。

---
Phase T：Target 检测（New Project, Unknown Vulns）
这部分是你最担心的：没有漏洞点，怎么做？
T0：候选提取（全项目自动）
输入：target db
输出：semantic_candidates.json（更大规模）
T1：LLM 标注（候选级别）
输入：candidates
输出：SemanticFacts.json
T2：Build Project Semantic Pack（项目适配层）
输出：ProjectSemantics.qll（该项目的适配包）
T3：Run Official Queries + ProjectSemantics
输入：target db + baseline queries + semantic pack
输出：SARIF findings（未知漏洞候选）
这就是你们的“检测新漏洞”流程。
它不依赖已知漏洞点。

---
3. 回答你最尖锐的质疑：这和“直接对新项目提取参数+LLM 判断”有什么区别？
你的替代方案其实就是 T0–T3。区别在于：
- 如果没有 seed 学习阶段，你不知道：
  - 对 overflow 到底该优先补哪里（BufferAccess vs taint）
  - 模板要长什么样才会真正被官方规则消费
  - 哪些候选提取信号有效，哪些是噪声
- 你会陷入“做了很多标注但规则不生效”的黑洞，且很难归因
seed 阶段的价值是：
- 用可证伪的已知真值（seed vuln）来调试整个适配器生成器
- 让你最终有信心在新项目上跑 T0–T3

---
4. 这套描述为什么“不会被审稿人击穿”？
审稿人最常见的攻击点是：
1. “你们只是给已知漏洞写补丁”
2. “你们没有泛化能力”
3. “LLM 幻觉导致不可控”
你用上面定义可以逐条回答：
- 我们的输出不是单个 query，而是项目适配层（ProjectSemantics pack）
- 泛化不体现在“一个规则通杀”，而体现在“适配流程自动化 + 模板复用”
- LLM 不写规则，只写结构化 facts；CodeQL 负责证伪；模板固定约束输出空间

---
5. 你下一步应该做什么（最关键、最具体）
为了让你彻底不再模糊，我建议你们立刻把实现改成下面两点（否则永远解释不清）：
1. LLM 输出改为 SemanticFacts.json，不要直接输出 qll
2. 实现三条候选提取 query（wrapper/capacity/guard），保证在新项目也能跑

---
如果你愿意，我下一步可以直接给你：
- SemanticCandidates.schema.json 与 SemanticFacts.schema.json
- 三条候选提取 CodeQL query 的 MVP 版本（召回优先）
- ProjectSemantics.qll.j2 的严格模板（确保生成至少一个 extends BufferAccess 子类）
- 以及一份“论文写法”的 Method + Ablation（seed 学习 vs 无 seed 直接适配）
这样你不仅“理解流程”，还会马上拥有一套能真正用于新项目的可复用资产。